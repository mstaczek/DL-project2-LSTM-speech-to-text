{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU27LLSTnu16"
      },
      "outputs": [],
      "source": [
        "# !7z x drive/MyDrive/dl2/train.7z -odrive/MyDrive/dl2/extracted/train\n",
        "# !find drive/MyDrive/dl2/extracted/train -type f | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e5SgjwtfJ3Jq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ekiVl7x-fy"
      },
      "source": [
        "# START"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HThH7DdaZn0r",
        "outputId": "c4d56bb1-32ea-49f0-af97-988b65d5439c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from scipy.io import wavfile\n",
        "import whisper\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "random.seed(123)\n",
        "\n",
        "def force_cudnn_initialization():\n",
        "    s = 2\n",
        "    dev = torch.device('cuda')\n",
        "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
        "if torch.cuda.is_available():\n",
        "    force_cudnn_initialization()\n",
        "else:\n",
        "    print('No cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6z8zIsYfCPj"
      },
      "source": [
        "## Listing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dJUdSj1fE8A",
        "outputId": "c5e28c7b-f105-491e-b501-39be8312546e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30 train classes\n",
            "['bed', 'five', 'bird', 'eight', 'happy', 'house', 'go', 'left', 'four', 'dog']\n",
            "['cat', 'down', 'no', 'seven', 'nine', 'right', 'marvin', 'on', 'off', 'one']\n",
            "['sheila', 'six', 'yes', 'zero', 'wow', 'up', 'tree', 'two', 'stop', 'three']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "root_path = 'drive/MyDrive/dl2/extracted/'\n",
        "train_path = root_path + 'train/train/audio/'\n",
        "test_path = root_path + 'test/test/audio/'\n",
        "\n",
        "train_classes_names = [c for c in os.listdir(train_path) if c != '_background_noise_']\n",
        "print(f\"Found {len(train_classes_names)} train classes\")\n",
        "print(train_classes_names[:10])\n",
        "print(train_classes_names[10:20])\n",
        "print(train_classes_names[20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP2C4sw6KHPM"
      },
      "source": [
        "# Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qXk81x-QxQJR"
      },
      "outputs": [],
      "source": [
        "class WhisperDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, train_path, size=None, selected_class=None):\n",
        "        train_classes_names = os.listdir(train_path)\n",
        "        self.dataset = []\n",
        "        train_classes_names = [c for c in train_classes_names if c != '_background_noise_']\n",
        "        train_classes_paths = [train_path + f for f in train_classes_names]\n",
        "        image_filenames = []\n",
        "        image_filenames_by_class = {}\n",
        "        for class_name in train_classes_names:\n",
        "            filenames = os.listdir(train_path + class_name)\n",
        "            image_filenames_by_class[class_name] = []\n",
        "            for filename in filenames:\n",
        "                image_filenames.append((train_path, class_name, '/' , filename))\n",
        "                image_filenames_by_class[class_name].append((train_path, class_name, '/' , filename))\n",
        "        \n",
        "        if selected_class != None:\n",
        "            image_filenames_by_class = {selected_class: image_filenames_by_class[selected_class]}\n",
        "            image_filenames = image_filenames_by_class[selected_class]\n",
        "\n",
        "        if size != None and size > 0:\n",
        "            image_filenames_selected = [] \n",
        "            size_per_class = round(size/len(image_filenames_by_class))\n",
        "            print(f'Recordings per class: {size_per_class}')\n",
        "            for class_name, class_filenames in image_filenames_by_class.items():\n",
        "                print(f'class {class_name} - recordings found: {len(class_filenames)}')\n",
        "                selected_from_this_class = random.sample(class_filenames, size_per_class)\n",
        "                image_filenames_selected += selected_from_this_class\n",
        "            image_filenames = image_filenames_selected\n",
        "        \n",
        "\n",
        "        for long_filename in tqdm(image_filenames):\n",
        "            train_path, class_name, slash, filename = long_filename\n",
        "            whole_filename_path = train_path + class_name + '/' + filename\n",
        "            bitrate, array_file = wavfile.read(whole_filename_path)\n",
        "            audio = torch.tensor(array_file).to(torch.float)\n",
        "            # audio = whisper.pad_or_trim(audio.flatten())\n",
        "            assert bitrate == 16000\n",
        "            \n",
        "            self.dataset.append((train_path, class_name, '/' , filename, audio))\n",
        "\n",
        "            # mel = whisper.log_mel_spectrogram(audio)\n",
        "            # self.dataset.append((mel, class_name))\n",
        "              \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        train_path, class_name, slash, filename, audio = self.dataset[item]\n",
        "\n",
        "        audio = whisper.pad_or_trim(audio.flatten())\n",
        "        mel = whisper.log_mel_spectrogram(audio)\n",
        "\n",
        "        return (mel, class_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxOXBD_yxNHX"
      },
      "source": [
        "# Exporting datasets to pickles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "89UbHkC4xTS7"
      },
      "outputs": [],
      "source": [
        "# trainsets_root = '/content/drive/MyDrive/dl2/train_dataset/'\n",
        "# for class_name in train_classes_names:\n",
        "#     SIZE = -1\n",
        "#     print(f'Starting class: {class_name}')\n",
        "#     train_dataset = WhisperDataset(train_path, size=SIZE, selected_class=class_name)\n",
        "#     pickled_name = f'trainset_class_{class_name}_size_{len(train_dataset)}.pt'\n",
        "#     torch.save(train_dataset, trainsets_root + pickled_name)\n",
        "#     print(f'Saved class: {class_name} to {pickled_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR_Q-JDY0sRF"
      },
      "source": [
        "# Loading ready datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noySTxhpzbXE",
        "outputId": "19d7c0c1-264f-4240-81e5-9c01defc4c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available datasets: 30\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bed': 'trainset_class_bed_size_1713.pt',\n",
              " 'five': 'trainset_class_five_size_2357.pt',\n",
              " 'bird': 'trainset_class_bird_size_1731.pt',\n",
              " 'eight': 'trainset_class_eight_size_2352.pt',\n",
              " 'happy': 'trainset_class_happy_size_1742.pt',\n",
              " 'house': 'trainset_class_house_size_1750.pt',\n",
              " 'go': 'trainset_class_go_size_2372.pt',\n",
              " 'left': 'trainset_class_left_size_2353.pt',\n",
              " 'four': 'trainset_class_four_size_2372.pt',\n",
              " 'dog': 'trainset_class_dog_size_1746.pt',\n",
              " 'cat': 'trainset_class_cat_size_1733.pt',\n",
              " 'down': 'trainset_class_down_size_2359.pt',\n",
              " 'no': 'trainset_class_no_size_2375.pt',\n",
              " 'seven': 'trainset_class_seven_size_2377.pt',\n",
              " 'nine': 'trainset_class_nine_size_2364.pt',\n",
              " 'right': 'trainset_class_right_size_2367.pt',\n",
              " 'marvin': 'trainset_class_marvin_size_1746.pt',\n",
              " 'on': 'trainset_class_on_size_2367.pt',\n",
              " 'off': 'trainset_class_off_size_2357.pt',\n",
              " 'one': 'trainset_class_one_size_2370.pt',\n",
              " 'sheila': 'trainset_class_sheila_size_1734.pt',\n",
              " 'six': 'trainset_class_six_size_2369.pt',\n",
              " 'yes': 'trainset_class_yes_size_2377.pt',\n",
              " 'zero': 'trainset_class_zero_size_2376.pt',\n",
              " 'wow': 'trainset_class_wow_size_1745.pt',\n",
              " 'up': 'trainset_class_up_size_2375.pt',\n",
              " 'tree': 'trainset_class_tree_size_1733.pt',\n",
              " 'two': 'trainset_class_two_size_2373.pt',\n",
              " 'stop': 'trainset_class_stop_size_2380.pt',\n",
              " 'three': 'trainset_class_three_size_2356.pt'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "trainsets_root = '/content/drive/MyDrive/dl2/train_dataset/'\n",
        "datasets_pickles_names = {v.split('_')[2] : v for v in os.listdir(trainsets_root)}\n",
        "# datasets_dict = {k:torch.load(trainsets_root + v) for k, v in datasets_pickles_names.items()} # load all datasets\n",
        "\n",
        "def load_ready_dataset(class_name):\n",
        "    trainsets_root = '/content/drive/MyDrive/dl2/train_dataset/'\n",
        "    datasets_pickles_names = {v.split('_')[2] : v for v in os.listdir(trainsets_root)} \n",
        "    return torch.load(trainsets_root + datasets_pickles_names[class_name])\n",
        "\n",
        "print(f'Available datasets: {len(datasets_pickles_names)}')\n",
        "datasets_pickles_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYVR_gbM3T0_"
      },
      "source": [
        "# Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B44fvp22x3B7"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "random.seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "N-yE7xxIdAhQ"
      },
      "outputs": [],
      "source": [
        "# DONE:\n",
        "# CLASS_NAME = 'dog'\n",
        "\n",
        "# CLASS_NAME = 'zero'\n",
        "# CLASS_NAME = 'one'\n",
        "# CLASS_NAME = 'two'\n",
        "# CLASS_NAME = 'three'\n",
        "# CLASS_NAME = 'four'\n",
        "# CLASS_NAME = 'five'\n",
        "\n",
        "# CLASS_NAME = 'yes'\n",
        "# CLASS_NAME = 'no'\n",
        "# CLASS_NAME = 'left'\n",
        "# CLASS_NAME = 'right'\n",
        "# CLASS_NAME = 'up'\n",
        "# CLASS_NAME = 'down'\n",
        "# CLASS_NAME = 'go'\n",
        "# CLASS_NAME = 'stop'\n",
        "# CLASS_NAME = 'off'\n",
        "# CLASS_NAME = 'on'\n",
        "\n",
        "\n",
        "# TODO:\n",
        "\n",
        "# CLASS_NAME = 'wow'\n",
        "# CLASS_NAME = 'bed'\n",
        "# CLASS_NAME = 'marvin'\n",
        "# CLASS_NAME = 'sheila'\n",
        "# CLASS_NAME = 'tree'\n",
        "# CLASS_NAME = 'bird'\n",
        "# CLASS_NAME = 'happy'\n",
        "# CLASS_NAME = 'cat'\n",
        "# CLASS_NAME = 'house'\n",
        "\n",
        "# CLASS_NAME = 'six'\n",
        "# CLASS_NAME = 'seven'\n",
        "# CLASS_NAME = 'eight'\n",
        "# CLASS_NAME = 'nine'\n",
        "\n",
        "train_dataset = load_ready_dataset(CLASS_NAME)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG0jdPqwKm2o",
        "outputId": "8eaad5d5-8b06-4cae-fc79-4e2966491b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 148/148 [11:20<00:00,  4.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4535\n",
            "Filename raw: /content/drive/MyDrive/dl2/per_class_results/model_medium.en_train_0.4535_class_five_size_2357_raw.csv\n",
            "  hypothesis reference\n",
            "0      Five.      five\n",
            "1      B A B      five\n",
            "2         Hi      five\n",
            "3  I'm fine.      five\n",
            "4        Bye      five\n",
            "Filename: /content/drive/MyDrive/dl2/per_class_results/model_medium.en_train_0.4535_class_five_size_2357.csv\n",
            "  hypothesis reference\n",
            "0       five      five\n",
            "1        bab      five\n",
            "2         hi      five\n",
            "3    i'mfine      five\n",
            "4        bye      five\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = 'medium.en' \n",
        "\n",
        "per_class_root = '/content/drive/MyDrive/dl2/per_class_results/'\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import whisper\n",
        "model = whisper.load_model(MODEL_NAME)\n",
        "device = 'cuda'\n",
        "\n",
        "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "for mels, texts in tqdm(train_loader):\n",
        "    mels = mels.to(device)\n",
        "    results = model.decode(mels, options)\n",
        "    hypotheses.extend([result.text for result in results])\n",
        "    references.extend(texts)\n",
        "\n",
        "def clean_prediction(text):\n",
        "    return text.lower().replace('.','').replace('?','').replace(' ','').replace('!','')\n",
        "\n",
        "size = len(train_dataset)\n",
        "\n",
        "\n",
        "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "hypotheses_clean = [clean_prediction(h) for h in hypotheses]\n",
        "data_clean = pd.DataFrame(dict(hypothesis=hypotheses_clean, reference=references))\n",
        "\n",
        "accuracy = len(data_clean[data_clean['hypothesis'] == data_clean['reference']]) / size\n",
        "print(f'Accuracy: {round(accuracy,4)}')\n",
        "\n",
        "results_filename_prefix = per_class_root + f'model_{MODEL_NAME}_train_{round(accuracy,4)}_class_{CLASS_NAME}_size_{size}'\n",
        "\n",
        "raw_filename = results_filename_prefix + '_raw.csv'\n",
        "print(f\"Filename raw: {raw_filename}\")\n",
        "data.to_csv(raw_filename)\n",
        "print(data.head(5))\n",
        "\n",
        "clean_filename = results_filename_prefix + '.csv'\n",
        "print(f\"Filename: {clean_filename}\")\n",
        "data_clean.to_csv(clean_filename)\n",
        "print(data_clean.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2i6BO6T7u6m"
      },
      "source": [
        "## Multiclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LsiqEMbI5yu"
      },
      "outputs": [],
      "source": [
        "SIZE = 1000\n",
        "train_dataset = WhisperDataset(train_path, size=SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_kozmnl2crH"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "ZG3S3qLXtBmd",
        "outputId": "23eb8b29-c6da-43ef-bdee-2387d03e8728"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:30<00:00, 49.9MiB/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1ff84611ef95>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mhypotheses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mreferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mn_audio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0maudio_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_audio_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# encoder forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_get_audio_features\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0maudio_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0maudio_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         if audio_features.dtype != (\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mmel\u001b[0m \u001b[0mspectrogram\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, x, weight, bias)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     ) -> Tensor:\n\u001b[0;32m---> 48\u001b[0;31m         return super()._conv_forward(\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \"slow_conv2d_cpu\" not implemented for 'Half'"
          ]
        }
      ],
      "source": [
        "# available models = ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', \n",
        "# 'medium.en', 'medium', 'large-v1', 'large-v2', 'large']\n",
        "\n",
        "# MODEL_NAME = 'tiny.en' # 0.0005 acc\n",
        "# MODEL_NAME = 'base.en' # 0.0043 acc\n",
        "# MODEL_NAME = 'small.en' # 0.1716 acc\n",
        "MODEL_NAME = 'medium.en' # 0.5080 acc\n",
        "# MODEL_NAME = 'large' # 0.5010 acc\n",
        "# MODEL_NAME = 'large-v2' #0.4980 acc\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import whisper\n",
        "model = whisper.load_model(MODEL_NAME)\n",
        "device = 'cuda'\n",
        "\n",
        "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "def clean_prediction(text):\n",
        "    return text.lower().replace('.','').replace('?','').replace(' ','')\n",
        "\n",
        "for mels, texts in tqdm(train_loader):\n",
        "    mels = mels.to(device)\n",
        "    results = model.decode(mels, options)\n",
        "    hypotheses.extend([result.text for result in results])\n",
        "    references.extend(texts)\n",
        "\n",
        "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "\n",
        "hypotheses_clean = [clean_prediction(h) for h in hypotheses]\n",
        "data_clean = pd.DataFrame(dict(hypothesis=hypotheses_clean, reference=references))\n",
        "accuracy = len(data_clean[data_clean['hypothesis'] == data_clean['reference']]) / len(data_clean)\n",
        "\n",
        "print(f'Accuracy: {round(accuracy,4)}')\n",
        "\n",
        "raw_filename = root_path + MODEL_NAME + f'_train_{round(accuracy,4)}_size_{SIZE}_raw.csv'\n",
        "print(f\"Filename raw: {raw_filename}\")\n",
        "data.to_csv(raw_filename)\n",
        "print(data.head(5))\n",
        "\n",
        "clean_filename = root_path + MODEL_NAME + f'_train_{round(accuracy,4)}_size_{SIZE}.csv'\n",
        "print(f\"Filename: {clean_filename}\")\n",
        "data_clean.to_csv(clean_filename)\n",
        "print(data_clean.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0CFWEtF-xv0"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "df = deepcopy(data_clean)\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if df.loc[i,'hypothesis'] not in train_classes_names:\n",
        "        df.loc[i,'hypothesis'] = 'mistake'\n",
        "df_confusion = pd.crosstab(df['reference'], df['hypothesis'])\n",
        "fig, ax = plt.subplots(figsize=(15,10)) \n",
        "sns.heatmap(df_confusion, linewidths=1, annot=True, fmt='g')\n",
        "plt.title(f\"Whisper model {MODEL_NAME}, accuracy {round(accuracy,4)}, img per class: {int(len(df)/len(train_classes_names))}\")\n",
        "\n",
        "output_path = root_path + MODEL_NAME + f'_train_{round(accuracy,4)}_size_{SIZE}.png'\n",
        "fig.savefig(output_path)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hS8PZ7N1SL9"
      },
      "source": [
        "## Large 1000 start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1wSD2mb1Rcg",
        "outputId": "33756bbc-8306-47e3-fc01-a253c8c59041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  hypothesis reference\n",
            "0       stop      stop\n",
            "1       tree      tree\n",
            "2        off       off\n",
            "3         go        go\n",
            "4      house     house\n",
            "Accuracy: 0.501\n",
            "Filename: drive/MyDrive/dl2/extracted/large_train_0.501_size_1000.csv\n"
          ]
        }
      ],
      "source": [
        "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "print(data.head(5))\n",
        "accuracy = len(data[data['hypothesis'] == data['reference']]) / len(data)\n",
        "print(f'Accuracy: {round(accuracy,4)}')\n",
        "print(f\"Filename: {root_path + MODEL_NAME + f'_train_{round(accuracy,4)}_size_{SIZE}.csv'}\")\n",
        "data.to_csv(root_path + MODEL_NAME + f'_train_{round(accuracy,4)}_size_{SIZE}.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5AVr22O1Y9e",
        "outputId": "d0aa0b9a-fee8-4e82-8ea8-085a8834f2f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Same word length: 0.605\n"
          ]
        }
      ],
      "source": [
        "s = 0\n",
        "for i in range(len(data)):\n",
        "    if len(data.iloc[i,0]) == len(data.iloc[i,1]):\n",
        "        s += 1\n",
        "print(f'Same word length: {round(s/len(data), 4)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQlr4eyowdZ7"
      },
      "source": [
        "## Medium en 1000 start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj8I2qwxwdJ_",
        "outputId": "994f9335-bc93-4ab6-e451-a036bf0116d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  hypothesis reference\n",
            "0      right     right\n",
            "1        dog       dog\n",
            "2         no        no\n",
            "3       bird      bird\n",
            "4       stop      stop\n",
            "Accuracy: 0.5076\n",
            "Filename: drive/MyDrive/dl2/extracted/medium.en_train_0.5076_size_10000.csv\n"
          ]
        }
      ],
      "source": [
        "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "print(data.head(5))\n",
        "accuracy = len(data[data['hypothesis'] == data['reference']]) / len(data)\n",
        "print(f'Accuracy: {round(accuracy,4)}')\n",
        "print(f\"Filename: {root_path + MODEL_NAME + f'_train_{round(accuracy,4)}_size_{SIZE}.csv'}\")\n",
        "data.to_csv(root_path + MODEL_NAME + f'_train_{round(accuracy,4)}_size_{SIZE}.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2J26KNzvsrh",
        "outputId": "2c84c4e4-d034-48c6-dfeb-a6a3fd998fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Same word length: 0.6089\n"
          ]
        }
      ],
      "source": [
        "s = 0\n",
        "for i in range(len(data)):\n",
        "    if len(data.iloc[i,0]) == len(data.iloc[i,1]):\n",
        "        s += 1\n",
        "print(f'Same word length: {round(s/len(data), 4)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HngxOl3jwoTx",
        "outputId": "3dff2fbf-8865-4508-9b2b-c2583cbb469d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most common words:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'right': 458,\n",
              " 'dog': 347,\n",
              " 'no': 423,\n",
              " 'bird': 331,\n",
              " 'stop': 438,\n",
              " 'off': 425,\n",
              " 'one': 424,\n",
              " 'go': 402,\n",
              " 'tree': 322,\n",
              " 'happy': 316,\n",
              " 'six': 437,\n",
              " 'four': 442,\n",
              " 'eight': 434,\n",
              " 'three': 417,\n",
              " 'nine': 442,\n",
              " 'five': 429,\n",
              " 'left': 441,\n",
              " 'cat': 298,\n",
              " 'house': 319,\n",
              " 'sheila': 343,\n",
              " 'down': 435,\n",
              " 'seven': 434,\n",
              " 'on': 461,\n",
              " 'marvin': 278,\n",
              " 'two': 172,\n",
              " 'bed': 332}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "c = Counter(list(data.iloc[:,1].values.flatten()))\n",
        "print(\"Most common words:\")\n",
        "{k:v for k, v in dict(c).items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DxI3kv0whrd"
      },
      "source": [
        "## Medium en 1000 end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFWOmygdtsHX",
        "outputId": "6bc8a2bf-47f7-4840-edad-49a5436f261c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "203\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Counter({' bed': 83,\n",
              "         ' better': 1,\n",
              "         ' then': 2,\n",
              "         ' bud': 1,\n",
              "         ' better!': 1,\n",
              "         'sword': 1,\n",
              "         ' bad': 33,\n",
              "         ' everything': 1,\n",
              "         ' no': 1,\n",
              "         ' but': 3,\n",
              "         ' oh, that one': 1,\n",
              "         ' thank you': 1,\n",
              "         ' dead': 18,\n",
              "         ' good': 10,\n",
              "         '!': 1,\n",
              "         ' chair, there are some special questions to schedule that was very i had a hugely visit because of the informatism okay, sorry! okay, parliamentists are here, and have a long moment of': 1,\n",
              "         ' there': 2,\n",
              "         ' vein': 1,\n",
              "         ' fad': 1,\n",
              "         ' paid': 1,\n",
              "         ' presence dead': 1,\n",
              "         ' that': 2,\n",
              "         ' bet': 2,\n",
              "         ' hehe': 1,\n",
              "         ' good, bad': 1,\n",
              "         ' you bet': 1,\n",
              "         ' bed,': 1,\n",
              "         ' fed': 1,\n",
              "         ' god': 2,\n",
              "         ' good bet': 1,\n",
              "         ' bedy': 1,\n",
              "         ' ben': 5,\n",
              "         ' god!': 1,\n",
              "         ' that was bad': 1,\n",
              "         \" and i was like what's up bird\": 1,\n",
              "         ' bed cannons ice': 1,\n",
              "         ' thanks': 1,\n",
              "         \" that's\": 1,\n",
              "         \" i'm on it\": 1,\n",
              "         ' airgood 3000inner': 1,\n",
              "         ' bear!': 1,\n",
              "         'gets people in mind': 1,\n",
              "         ' beige': 1,\n",
              "         ' bed bicycles dashboard': 1,\n",
              "         \" and i'll give you a quick move on, guys thank you you're so good to go back in fact, there's the kansas city planting tree i was in the nob room for the\": 1,\n",
              "         \" c'siy girls don't care i just keep at it\": 1,\n",
              "         ' edhhh': 1,\n",
              "         ' … bet': 1,\n",
              "         ' lines, i was': 1,\n",
              "         '': 1,\n",
              "         ' meh': 1,\n",
              "         ' bread': 1})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = list(df[['result']].values.flatten())\n",
        "a = [b.lower().replace('.','').replace('?','') for b in a]\n",
        "from collections import Counter\n",
        "print(len(a))\n",
        "Counter(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvBNusAZttBJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv('drive/MyDrive/dl2/extracted/test1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utsE_Zrxr9Ax",
        "outputId": "1c7eff3a-1cde-4326-b279-82fca4642cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "284\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Counter({' bed': 217,\n",
              "         ' bad': 36,\n",
              "         ' i bet': 1,\n",
              "         ' but': 5,\n",
              "         ' bid': 3,\n",
              "         ' beds': 1,\n",
              "         ' bye': 3,\n",
              "         \" i'm bad\": 1,\n",
              "         ' in bed': 3,\n",
              "         ' dead': 4,\n",
              "         ' clear on you that': 1,\n",
              "         ' okay': 1,\n",
              "         ' bed!': 1,\n",
              "         ' bet': 2,\n",
              "         ' better': 1,\n",
              "         ' fed': 1,\n",
              "         ' beard': 1,\n",
              "         ' ed': 1,\n",
              "         ' bae-d': 1})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = list(df[['result']].values.flatten())\n",
        "a = [b.lower().replace('.','').replace('?','') for b in a]\n",
        "from collections import Counter\n",
        "print(len(a))\n",
        "Counter(a)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}